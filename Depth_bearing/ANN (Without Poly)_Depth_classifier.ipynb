{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd40506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cbc1b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Input data\n",
    "data_cohesion = np.load('Inputs/4ft_cohesion.npy')\n",
    "data_cohesion = data_cohesion[0:16,:]\n",
    "data_friction = np.load('Inputs/4ft_friction.npy')\n",
    "data_friction = data_friction[0:16,:]\n",
    "data_watertable = np.load('Inputs/4ft_water_table.npy')\n",
    "data_watertable = np.squeeze(data_watertable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59973bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing output Data\n",
    "data_depth = np.load('Targets/4ft_failure_depths.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "740d7550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284107, 16)\n",
      "(284107, 16)\n",
      "(284107,)\n",
      "(284107,)\n"
     ]
    }
   ],
   "source": [
    "#Size\n",
    "data_cohesion = np.transpose(data_cohesion)\n",
    "data_friction = np.transpose(data_friction)\n",
    "data_watertable = np.transpose(data_watertable)\n",
    "data_watertable = np.squeeze(data_watertable)\n",
    "data_depth = np.squeeze(data_depth)\n",
    "print(np.shape(data_cohesion))\n",
    "print(np.shape(data_friction))\n",
    "print(np.shape(data_watertable))\n",
    "print(np.shape(data_depth))\n",
    "n_y = 25\n",
    "n_x =33\n",
    "n_sim = np.shape(data_cohesion)[0]\n",
    "n_final_test = 107\n",
    "n_remain = n_sim - n_final_test\n",
    "m = np.shape(data_cohesion)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2813a25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr= np.zeros((n_remain,2*m + 2))\n",
    "data_arr[0:n_remain,0:m] = data_cohesion[0:n_remain,:]\n",
    "data_arr[0:n_remain,m:2*m] = data_friction[0:n_remain,:]\n",
    "data_arr[0:n_remain,2*m] = data_watertable[0:n_remain]\n",
    "data_arr[0:n_remain,2*m+1] = data_depth[0:n_remain]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd4c99c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "data_val= np.zeros((n_final_test,2*m+2))\n",
    "data_val[:,0:m] = data_cohesion[n_remain:n_sim,:]\n",
    "data_val[:,m:2*m] = data_friction[n_remain:n_sim,:]\n",
    "data_val[:,2*m] = data_watertable[n_remain:n_sim]\n",
    "data_val[:,2*m+1] = data_depth[n_remain:n_sim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1010d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data_arr[:,:-1]\n",
    "data_y = data_arr[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5949573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9 22  3 ...  8  5  8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(data_y)\n",
    "print(integer_encoded)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "\n",
    "### One hot encoding\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24150585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aaece00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting test and training\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, onehot_encoded, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6720e021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2169235",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann1 = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73f3a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the input and first hidden layer, will be adding a dense layer\n",
    "ann1.add(tf.keras.layers.Dense(units = 256,activation = 'relu'))\n",
    "ann1.add(tf.keras.layers.Dense(units = 128,activation = 'relu'))\n",
    "ann1.add(tf.keras.layers.Dense(units = 64, activation = 'relu'))\n",
    "ann1.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))\n",
    "#Output Layer\n",
    "ann1.add(tf.keras.layers.Dense(units = 24, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2d3bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compling ann\n",
    "ann1.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5250808f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1775/1775 [==============================] - 15s 7ms/step - loss: 1.1474 - accuracy: 0.6072\n",
      "Epoch 2/100\n",
      "1775/1775 [==============================] - 12s 7ms/step - loss: 0.7788 - accuracy: 0.7139\n",
      "Epoch 3/100\n",
      "1775/1775 [==============================] - 15s 9ms/step - loss: 0.6953 - accuracy: 0.7420\n",
      "Epoch 4/100\n",
      "1775/1775 [==============================] - 17s 10ms/step - loss: 0.6495 - accuracy: 0.7577\n",
      "Epoch 5/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.6190 - accuracy: 0.7684\n",
      "Epoch 6/100\n",
      "1775/1775 [==============================] - 17s 9ms/step - loss: 0.5913 - accuracy: 0.7792\n",
      "Epoch 7/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.5691 - accuracy: 0.7865\n",
      "Epoch 8/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.5503 - accuracy: 0.7936\n",
      "Epoch 9/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.5362 - accuracy: 0.7986\n",
      "Epoch 10/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.5238 - accuracy: 0.8029\n",
      "Epoch 11/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.5103 - accuracy: 0.8083\n",
      "Epoch 12/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.4999 - accuracy: 0.8120\n",
      "Epoch 13/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.4899 - accuracy: 0.8156\n",
      "Epoch 14/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.4805 - accuracy: 0.8190\n",
      "Epoch 15/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.4730 - accuracy: 0.8213\n",
      "Epoch 16/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.4648 - accuracy: 0.8245\n",
      "Epoch 17/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.4565 - accuracy: 0.8283\n",
      "Epoch 18/100\n",
      "1775/1775 [==============================] - 15s 9ms/step - loss: 0.4499 - accuracy: 0.8303\n",
      "Epoch 19/100\n",
      "1775/1775 [==============================] - 15s 9ms/step - loss: 0.4427 - accuracy: 0.8327\n",
      "Epoch 20/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.4365 - accuracy: 0.8351\n",
      "Epoch 21/100\n",
      "1775/1775 [==============================] - 17s 9ms/step - loss: 0.4305 - accuracy: 0.8382\n",
      "Epoch 22/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.4238 - accuracy: 0.8403\n",
      "Epoch 23/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.4192 - accuracy: 0.8417\n",
      "Epoch 24/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.4155 - accuracy: 0.8436\n",
      "Epoch 25/100\n",
      "1775/1775 [==============================] - 17s 10ms/step - loss: 0.4107 - accuracy: 0.8447\n",
      "Epoch 26/100\n",
      "1775/1775 [==============================] - 17s 9ms/step - loss: 0.4057 - accuracy: 0.8467\n",
      "Epoch 27/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.4007 - accuracy: 0.8491\n",
      "Epoch 28/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.3958 - accuracy: 0.8498\n",
      "Epoch 29/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.3929 - accuracy: 0.8518\n",
      "Epoch 30/100\n",
      "1775/1775 [==============================] - 17s 10ms/step - loss: 0.3885 - accuracy: 0.8535\n",
      "Epoch 31/100\n",
      "1775/1775 [==============================] - 17s 9ms/step - loss: 0.3851 - accuracy: 0.8542\n",
      "Epoch 32/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.3804 - accuracy: 0.8558\n",
      "Epoch 33/100\n",
      "1775/1775 [==============================] - 17s 10ms/step - loss: 0.3766 - accuracy: 0.8579\n",
      "Epoch 34/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.3751 - accuracy: 0.8578\n",
      "Epoch 35/100\n",
      "1775/1775 [==============================] - 17s 10ms/step - loss: 0.3710 - accuracy: 0.8599\n",
      "Epoch 36/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.3676 - accuracy: 0.8611\n",
      "Epoch 37/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.3635 - accuracy: 0.8620\n",
      "Epoch 38/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.3622 - accuracy: 0.8626\n",
      "Epoch 39/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.3581 - accuracy: 0.8641\n",
      "Epoch 40/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.3565 - accuracy: 0.8650\n",
      "Epoch 41/100\n",
      "1775/1775 [==============================] - 17s 9ms/step - loss: 0.3507 - accuracy: 0.8671\n",
      "Epoch 42/100\n",
      "1775/1775 [==============================] - 17s 9ms/step - loss: 0.3500 - accuracy: 0.8669\n",
      "Epoch 43/100\n",
      "1775/1775 [==============================] - 17s 9ms/step - loss: 0.3466 - accuracy: 0.8691\n",
      "Epoch 44/100\n",
      "1775/1775 [==============================] - 17s 9ms/step - loss: 0.3450 - accuracy: 0.8696\n",
      "Epoch 45/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.3426 - accuracy: 0.8703\n",
      "Epoch 46/100\n",
      "1775/1775 [==============================] - 17s 9ms/step - loss: 0.3395 - accuracy: 0.8712\n",
      "Epoch 47/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.3367 - accuracy: 0.8723\n",
      "Epoch 48/100\n",
      "1775/1775 [==============================] - 17s 9ms/step - loss: 0.3349 - accuracy: 0.8726\n",
      "Epoch 49/100\n",
      "1775/1775 [==============================] - 17s 9ms/step - loss: 0.3332 - accuracy: 0.8735\n",
      "Epoch 50/100\n",
      "1775/1775 [==============================] - 17s 10ms/step - loss: 0.3302 - accuracy: 0.8745\n",
      "Epoch 51/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.3278 - accuracy: 0.8754\n",
      "Epoch 52/100\n",
      "1775/1775 [==============================] - 17s 10ms/step - loss: 0.3259 - accuracy: 0.8764\n",
      "Epoch 53/100\n",
      "1775/1775 [==============================] - 17s 9ms/step - loss: 0.3227 - accuracy: 0.8772\n",
      "Epoch 54/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.3214 - accuracy: 0.8781\n",
      "Epoch 55/100\n",
      "1775/1775 [==============================] - 17s 10ms/step - loss: 0.3192 - accuracy: 0.8791\n",
      "Epoch 56/100\n",
      "1775/1775 [==============================] - 17s 10ms/step - loss: 0.3183 - accuracy: 0.8792\n",
      "Epoch 57/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.3158 - accuracy: 0.8796\n",
      "Epoch 58/100\n",
      "1775/1775 [==============================] - 17s 9ms/step - loss: 0.3142 - accuracy: 0.8806\n",
      "Epoch 59/100\n",
      "1775/1775 [==============================] - 17s 9ms/step - loss: 0.3110 - accuracy: 0.8813\n",
      "Epoch 60/100\n",
      "1775/1775 [==============================] - 17s 9ms/step - loss: 0.3109 - accuracy: 0.8815\n",
      "Epoch 61/100\n",
      "1775/1775 [==============================] - 17s 10ms/step - loss: 0.3073 - accuracy: 0.8835\n",
      "Epoch 62/100\n",
      "1775/1775 [==============================] - 17s 10ms/step - loss: 0.3058 - accuracy: 0.8844\n",
      "Epoch 63/100\n",
      "1775/1775 [==============================] - 16s 9ms/step - loss: 0.3054 - accuracy: 0.8832\n",
      "Epoch 64/100\n",
      "1775/1775 [==============================] - 17s 9ms/step - loss: 0.3039 - accuracy: 0.8847\n",
      "Epoch 65/100\n",
      "1775/1775 [==============================] - 15s 9ms/step - loss: 0.3008 - accuracy: 0.8856\n",
      "Epoch 66/100\n",
      "1775/1775 [==============================] - 12s 7ms/step - loss: 0.3009 - accuracy: 0.8853\n",
      "Epoch 67/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2980 - accuracy: 0.8869\n",
      "Epoch 68/100\n",
      "1775/1775 [==============================] - 12s 7ms/step - loss: 0.2970 - accuracy: 0.8872\n",
      "Epoch 69/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2969 - accuracy: 0.8872\n",
      "Epoch 70/100\n",
      "1775/1775 [==============================] - 10s 6ms/step - loss: 0.2950 - accuracy: 0.8880\n",
      "Epoch 71/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2927 - accuracy: 0.8882\n",
      "Epoch 72/100\n",
      "1775/1775 [==============================] - 12s 7ms/step - loss: 0.2935 - accuracy: 0.8887\n",
      "Epoch 73/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2904 - accuracy: 0.8900\n",
      "Epoch 74/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2888 - accuracy: 0.8903\n",
      "Epoch 75/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2882 - accuracy: 0.8904\n",
      "Epoch 76/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2861 - accuracy: 0.8915\n",
      "Epoch 77/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2852 - accuracy: 0.8916\n",
      "Epoch 78/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2843 - accuracy: 0.8915\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2828 - accuracy: 0.8921\n",
      "Epoch 80/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2805 - accuracy: 0.8933\n",
      "Epoch 81/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2804 - accuracy: 0.8932\n",
      "Epoch 82/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2780 - accuracy: 0.8943\n",
      "Epoch 83/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2778 - accuracy: 0.8939\n",
      "Epoch 84/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2763 - accuracy: 0.8952\n",
      "Epoch 85/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2769 - accuracy: 0.8944\n",
      "Epoch 86/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2742 - accuracy: 0.8952\n",
      "Epoch 87/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2741 - accuracy: 0.8953\n",
      "Epoch 88/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2717 - accuracy: 0.8967\n",
      "Epoch 89/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2719 - accuracy: 0.8963\n",
      "Epoch 90/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2699 - accuracy: 0.8964\n",
      "Epoch 91/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2679 - accuracy: 0.8982\n",
      "Epoch 92/100\n",
      "1775/1775 [==============================] - 11s 6ms/step - loss: 0.2676 - accuracy: 0.8981\n",
      "Epoch 93/100\n",
      "1775/1775 [==============================] - 7s 4ms/step - loss: 0.2663 - accuracy: 0.8985\n",
      "Epoch 94/100\n",
      "1775/1775 [==============================] - 7s 4ms/step - loss: 0.2661 - accuracy: 0.8985\n",
      "Epoch 95/100\n",
      "1775/1775 [==============================] - 7s 4ms/step - loss: 0.2665 - accuracy: 0.8981\n",
      "Epoch 96/100\n",
      "1775/1775 [==============================] - 7s 4ms/step - loss: 0.2620 - accuracy: 0.8998\n",
      "Epoch 97/100\n",
      "1775/1775 [==============================] - 7s 4ms/step - loss: 0.2649 - accuracy: 0.8987\n",
      "Epoch 98/100\n",
      "1775/1775 [==============================] - 7s 4ms/step - loss: 0.2618 - accuracy: 0.8996\n",
      "Epoch 99/100\n",
      "1775/1775 [==============================] - 7s 4ms/step - loss: 0.2623 - accuracy: 0.8996\n",
      "Epoch 100/100\n",
      "1775/1775 [==============================] - 7s 4ms/step - loss: 0.2603 - accuracy: 0.9004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2399ee72730>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#traing the model\n",
    "ann1.fit(x_train,y_train,batch_size = 128, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b049f041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1775/1775 [==============================] - 3s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b9eb563",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann1.save(\"ann_depth_classifier_without_poly.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a03e2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
