{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f698cecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from keras-tuner) (1.0.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from keras-tuner) (1.21.5)\n",
      "Requirement already satisfied: ipython in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from keras-tuner) (8.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from keras-tuner) (2.27.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from keras-tuner) (21.3)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from keras-tuner) (2.9.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.7.5)\n",
      "Requirement already satisfied: backcall in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (5.1.1)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (5.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.4.4)\n",
      "Requirement already satisfied: stack-data in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.1.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (3.0.20)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (61.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.18.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (2.11.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->keras-tuner) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from packaging->keras-tuner) (3.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from stack-data->ipython->keras-tuner) (0.2.2)\n",
      "Requirement already satisfied: executing in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from stack-data->ipython->keras-tuner) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from stack-data->ipython->keras-tuner) (2.0.5)\n",
      "Requirement already satisfied: six in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from asttokens->stack-data->ipython->keras-tuner) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (1.33.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (3.19.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (1.8.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (1.42.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (0.37.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (1.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (2.0.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n",
      "Requirement already satisfied: tensorflow_addons in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from tensorflow_addons) (2.13.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ssinghai\\anaconda3\\lib\\site-packages (from packaging->tensorflow_addons) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner\n",
    "!pip install tensorflow_addons\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6be8c8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fee37a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Input data\n",
    "data_cohesion = np.load('Inputs/4ft_cohesion.npy')\n",
    "data_friction = np.load('Inputs/4ft_friction.npy')\n",
    "data_poly = np.load('Inputs/4ft_poly_feature.npy')\n",
    "data_watertable = np.load('Inputs/4ft_water_table.npy')\n",
    "data_velo = np.load(\"Targets/4ft_velocity_plots.npy\")\n",
    "data_watertable = np.squeeze(data_watertable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5427e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144807, 16)\n",
      "(144807, 16)\n",
      "(144807,)\n",
      "(33, 33, 144807)\n"
     ]
    }
   ],
   "source": [
    "#Size\n",
    "data_cohesion = np.transpose(data_cohesion)\n",
    "data_friction = np.transpose(data_friction)\n",
    "data_watertable = np.transpose(data_watertable)\n",
    "data_watertable = np.squeeze(data_watertable)\n",
    "print(np.shape(data_cohesion))\n",
    "print(np.shape(data_friction))\n",
    "print(np.shape(data_watertable))\n",
    "print(np.shape(data_velo))\n",
    "m = np.shape(data_cohesion)[1]\n",
    "n_sim = np.shape(data_velo)[2]\n",
    "n_final_test = 0\n",
    "n_remain = n_sim - n_final_test\n",
    "mo = np.shape(data_velo)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6fe6cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "li= []\n",
    "for i in range (n_sim):\n",
    "    temp = np.reshape(data_velo[:,:,i],(mo*mo,1))\n",
    "    li.append(temp)\n",
    "data = np.array(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "206e8c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr= np.zeros((n_remain,2*m + 1))\n",
    "data_arr[0:n_remain,0:m] = data_cohesion[0:n_remain,:]\n",
    "data_arr[0:n_remain,m:2*m] = data_friction[0:n_remain,:]\n",
    "data_arr[0:n_remain,2*m] = data_watertable[0:n_remain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7aaa6452",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data_arr\n",
    "data_y = data[0:n_remain,:,:]\n",
    "data_y = np.reshape(data_y, (n_remain,mo*mo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae0fa63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y1 = np.zeros((np.shape(data_y)))\n",
    "for i in range(n_sim):\n",
    "    data_y1[i,:] = data_y[i,:]/np.max(data_y[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c637d5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144807, 1089)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6566fde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144807, 33)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7f47101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    for i in range(hp.Int('num_layers', 3, 10)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=512,\n",
    "                                            max_value=4068,\n",
    "                                            step=64),\n",
    "                               activation='relu'))\n",
    "    model.add(layers.Dense(1089, activation='linear'))\n",
    "    metric = tfa.metrics.r_square.RSquare()\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='mean_absolute_error',\n",
    "        metrics=[metric])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "893d8210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project project\\Velocity Field\\oracle.json\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mae',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='project',\n",
    "    project_name='Velocity Field')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d7c081d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 5\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 10, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 512, 'max_value': 4068, 'step': 64, 'sampling': None}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 512, 'max_value': 4068, 'step': 64, 'sampling': None}\n",
      "units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 512, 'max_value': 4068, 'step': 64, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec6a2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48db0ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y1, test_size=0.1, random_state = 42)\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09c5fce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "6                 |?                 |num_layers\n",
      "1920              |?                 |units_0\n",
      "3328              |?                 |units_1\n",
      "1856              |?                 |units_2\n",
      "0.001             |?                 |learning_rate\n",
      "512               |?                 |units_3\n",
      "512               |?                 |units_4\n",
      "512               |?                 |units_5\n",
      "\n",
      "Epoch 1/100\n",
      "4073/4073 [==============================] - 32s 8ms/step - loss: 0.0519 - r_square: 0.1310 - val_loss: 0.0425 - val_r_square: 0.3386\n",
      "Epoch 2/100\n",
      "4073/4073 [==============================] - 31s 8ms/step - loss: 0.0387 - r_square: 0.4254 - val_loss: 0.0359 - val_r_square: 0.4596\n",
      "Epoch 3/100\n",
      "4073/4073 [==============================] - 31s 8ms/step - loss: 0.0340 - r_square: 0.5112 - val_loss: 0.0335 - val_r_square: 0.5229\n",
      "Epoch 4/100\n",
      "4073/4073 [==============================] - 31s 8ms/step - loss: 0.0313 - r_square: 0.5540 - val_loss: 0.0314 - val_r_square: 0.5290\n",
      "Epoch 5/100\n",
      "4073/4073 [==============================] - 32s 8ms/step - loss: 0.0293 - r_square: 0.5796 - val_loss: 0.0290 - val_r_square: 0.5640\n",
      "Epoch 6/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0280 - r_square: 0.5956 - val_loss: 0.0288 - val_r_square: 0.5743\n",
      "Epoch 7/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0270 - r_square: 0.6082 - val_loss: 0.0281 - val_r_square: 0.5632\n",
      "Epoch 8/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0260 - r_square: 0.6195 - val_loss: 0.0274 - val_r_square: 0.5754\n",
      "Epoch 9/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0252 - r_square: 0.6297 - val_loss: 0.0268 - val_r_square: 0.5904\n",
      "Epoch 10/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0247 - r_square: 0.6342 - val_loss: 0.0259 - val_r_square: 0.5848\n",
      "Epoch 11/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0240 - r_square: 0.6449 - val_loss: 0.0260 - val_r_square: 0.5991\n",
      "Epoch 12/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0236 - r_square: 0.6506 - val_loss: 0.0258 - val_r_square: 0.5949\n",
      "Epoch 13/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0231 - r_square: 0.6563 - val_loss: 0.0258 - val_r_square: 0.6078\n",
      "Epoch 14/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0227 - r_square: 0.6615 - val_loss: 0.0250 - val_r_square: 0.6058\n",
      "Epoch 15/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0223 - r_square: 0.6663 - val_loss: 0.0255 - val_r_square: 0.6051\n",
      "Epoch 16/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0221 - r_square: 0.6705 - val_loss: 0.0244 - val_r_square: 0.6209\n",
      "Epoch 17/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0217 - r_square: 0.6751 - val_loss: 0.0243 - val_r_square: 0.6317\n",
      "Epoch 18/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0215 - r_square: 0.6795 - val_loss: 0.0238 - val_r_square: 0.6261\n",
      "Epoch 19/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0212 - r_square: 0.6828 - val_loss: 0.0241 - val_r_square: 0.6080\n",
      "Epoch 20/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0209 - r_square: 0.6864 - val_loss: 0.0237 - val_r_square: 0.6238\n",
      "Epoch 21/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0207 - r_square: 0.6913 - val_loss: 0.0238 - val_r_square: 0.6359\n",
      "Epoch 22/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0206 - r_square: 0.6912 - val_loss: 0.0238 - val_r_square: 0.6047\n",
      "Epoch 23/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0203 - r_square: 0.6962 - val_loss: 0.0239 - val_r_square: 0.6150\n",
      "Epoch 24/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0202 - r_square: 0.6988 - val_loss: 0.0237 - val_r_square: 0.6239\n",
      "Epoch 25/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0200 - r_square: 0.7004 - val_loss: 0.0229 - val_r_square: 0.6313\n",
      "Epoch 26/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0198 - r_square: 0.7023 - val_loss: 0.0232 - val_r_square: 0.6369\n",
      "Epoch 27/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0197 - r_square: 0.7038 - val_loss: 0.0233 - val_r_square: 0.6153\n",
      "Epoch 28/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0195 - r_square: 0.7050 - val_loss: 0.0228 - val_r_square: 0.6093\n",
      "Epoch 29/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0194 - r_square: 0.7084 - val_loss: 0.0230 - val_r_square: 0.6324\n",
      "Epoch 30/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0193 - r_square: 0.7113 - val_loss: 0.0231 - val_r_square: 0.6232\n",
      "Epoch 31/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0193 - r_square: 0.7100 - val_loss: 0.0230 - val_r_square: 0.6282\n",
      "Epoch 32/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0190 - r_square: 0.7133 - val_loss: 0.0237 - val_r_square: 0.5986\n",
      "Epoch 33/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0190 - r_square: 0.7117 - val_loss: 0.0228 - val_r_square: 0.6241\n",
      "Epoch 34/100\n",
      "4073/4073 [==============================] - 32s 8ms/step - loss: 0.0187 - r_square: 0.7161 - val_loss: 0.0230 - val_r_square: 0.6311\n",
      "Epoch 35/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0187 - r_square: 0.7178 - val_loss: 0.0229 - val_r_square: 0.6381\n",
      "Epoch 36/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0185 - r_square: 0.7215 - val_loss: 0.0227 - val_r_square: 0.6371\n",
      "Epoch 37/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0185 - r_square: 0.7215 - val_loss: 0.0224 - val_r_square: 0.6388\n",
      "Epoch 38/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0185 - r_square: 0.7206 - val_loss: 0.0224 - val_r_square: 0.6491\n",
      "Epoch 39/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0183 - r_square: 0.7239 - val_loss: 0.0222 - val_r_square: 0.6195\n",
      "Epoch 40/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0183 - r_square: 0.7227 - val_loss: 0.0221 - val_r_square: 0.6413\n",
      "Epoch 41/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0183 - r_square: 0.7252 - val_loss: 0.0223 - val_r_square: 0.6491\n",
      "Epoch 42/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0181 - r_square: 0.7270 - val_loss: 0.0221 - val_r_square: 0.6453\n",
      "Epoch 43/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0180 - r_square: 0.7275 - val_loss: 0.0223 - val_r_square: 0.6380\n",
      "Epoch 44/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0179 - r_square: 0.7289 - val_loss: 0.0222 - val_r_square: 0.6498\n",
      "Epoch 45/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0178 - r_square: 0.7304 - val_loss: 0.0226 - val_r_square: 0.6216\n",
      "Epoch 46/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0178 - r_square: 0.7311 - val_loss: 0.0225 - val_r_square: 0.6342\n",
      "Epoch 47/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0178 - r_square: 0.7318 - val_loss: 0.0221 - val_r_square: 0.6506\n",
      "Epoch 48/100\n",
      "4073/4073 [==============================] - 36s 9ms/step - loss: 0.0177 - r_square: 0.7344 - val_loss: 0.0222 - val_r_square: 0.6463\n",
      "Epoch 49/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0177 - r_square: 0.7351 - val_loss: 0.0225 - val_r_square: 0.6331\n",
      "Epoch 50/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0176 - r_square: 0.7338 - val_loss: 0.0218 - val_r_square: 0.6299\n",
      "Epoch 51/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0174 - r_square: 0.7367 - val_loss: 0.0217 - val_r_square: 0.6471\n",
      "Epoch 52/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0174 - r_square: 0.7353 - val_loss: 0.0223 - val_r_square: 0.6346\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4073/4073 [==============================] - 32s 8ms/step - loss: 0.0175 - r_square: 0.7353 - val_loss: 0.0220 - val_r_square: 0.6407\n",
      "Epoch 54/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0174 - r_square: 0.7373 - val_loss: 0.0226 - val_r_square: 0.6446\n",
      "Epoch 55/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0174 - r_square: 0.7371 - val_loss: 0.0218 - val_r_square: 0.6340\n",
      "Epoch 56/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0173 - r_square: 0.7385 - val_loss: 0.0218 - val_r_square: 0.6428\n",
      "Epoch 57/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0174 - r_square: 0.7372 - val_loss: 0.0221 - val_r_square: 0.6367\n",
      "Epoch 58/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0172 - r_square: 0.7414 - val_loss: 0.0219 - val_r_square: 0.6301\n",
      "Epoch 59/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0172 - r_square: 0.7405 - val_loss: 0.0220 - val_r_square: 0.6471\n",
      "Epoch 60/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0171 - r_square: 0.7420 - val_loss: 0.0217 - val_r_square: 0.6503\n",
      "Epoch 61/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0171 - r_square: 0.7397 - val_loss: 0.0222 - val_r_square: 0.6295\n",
      "Epoch 62/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0171 - r_square: 0.7405 - val_loss: 0.0222 - val_r_square: 0.6500\n",
      "Epoch 63/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0171 - r_square: 0.7419 - val_loss: 0.0218 - val_r_square: 0.6373\n",
      "Epoch 64/100\n",
      "4073/4073 [==============================] - 36s 9ms/step - loss: 0.0170 - r_square: 0.7418 - val_loss: 0.0227 - val_r_square: 0.6232\n",
      "Epoch 65/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0171 - r_square: 0.7432 - val_loss: 0.0221 - val_r_square: 0.6496\n",
      "Epoch 66/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0169 - r_square: 0.7430 - val_loss: 0.0218 - val_r_square: 0.6397\n",
      "Epoch 67/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0169 - r_square: 0.7438 - val_loss: 0.0219 - val_r_square: 0.6261\n",
      "Epoch 68/100\n",
      "4073/4073 [==============================] - 36s 9ms/step - loss: 0.0170 - r_square: 0.7434 - val_loss: 0.0220 - val_r_square: 0.6513\n",
      "Epoch 69/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0168 - r_square: 0.7469 - val_loss: 0.0221 - val_r_square: 0.6556\n",
      "Epoch 70/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0169 - r_square: 0.7446 - val_loss: 0.0219 - val_r_square: 0.6382\n",
      "Epoch 71/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0168 - r_square: 0.7464 - val_loss: 0.0220 - val_r_square: 0.6347\n",
      "Epoch 72/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0169 - r_square: 0.7409 - val_loss: 0.0219 - val_r_square: 0.6291\n",
      "Epoch 73/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0168 - r_square: 0.7438 - val_loss: 0.0219 - val_r_square: 0.6393\n",
      "Epoch 74/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0167 - r_square: 0.7452 - val_loss: 0.0224 - val_r_square: 0.6383\n",
      "Epoch 75/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0167 - r_square: 0.7468 - val_loss: 0.0218 - val_r_square: 0.6337\n",
      "Epoch 76/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0167 - r_square: 0.7477 - val_loss: 0.0219 - val_r_square: 0.6453\n",
      "Epoch 77/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0168 - r_square: 0.7454 - val_loss: 0.0221 - val_r_square: 0.6381\n",
      "Epoch 78/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0167 - r_square: 0.7473 - val_loss: 0.0219 - val_r_square: 0.6383\n",
      "Epoch 79/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0167 - r_square: 0.7464 - val_loss: 0.0227 - val_r_square: 0.6111\n",
      "Epoch 80/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0166 - r_square: 0.7478 - val_loss: 0.0222 - val_r_square: 0.6064\n",
      "Epoch 81/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0167 - r_square: 0.7453 - val_loss: 0.0220 - val_r_square: 0.6192\n",
      "Epoch 82/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0167 - r_square: 0.7466 - val_loss: 0.0218 - val_r_square: 0.6436\n",
      "Epoch 83/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0167 - r_square: 0.7439 - val_loss: 0.0220 - val_r_square: 0.6313\n",
      "Epoch 84/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0167 - r_square: 0.7448 - val_loss: 0.0220 - val_r_square: 0.6404\n",
      "Epoch 85/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0166 - r_square: 0.7470 - val_loss: 0.0224 - val_r_square: 0.6291\n",
      "Epoch 86/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0165 - r_square: 0.7475 - val_loss: 0.0222 - val_r_square: 0.6352\n",
      "Epoch 87/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0165 - r_square: 0.7481 - val_loss: 0.0217 - val_r_square: 0.6414\n",
      "Epoch 88/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0164 - r_square: 0.7477 - val_loss: 0.0228 - val_r_square: 0.6078\n",
      "Epoch 89/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0167 - r_square: 0.7445 - val_loss: 0.0220 - val_r_square: 0.6487\n",
      "Epoch 90/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0163 - r_square: 0.7500 - val_loss: 0.0222 - val_r_square: 0.6347\n",
      "Epoch 91/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0166 - r_square: 0.7438 - val_loss: 0.0227 - val_r_square: 0.6209\n",
      "Epoch 92/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0166 - r_square: 0.7452 - val_loss: 0.0221 - val_r_square: 0.6494\n",
      "Epoch 93/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0166 - r_square: 0.7486 - val_loss: 0.0219 - val_r_square: 0.6535\n",
      "Epoch 94/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0164 - r_square: 0.7473 - val_loss: 0.0220 - val_r_square: 0.6483\n",
      "Epoch 95/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0165 - r_square: 0.7473 - val_loss: 0.0217 - val_r_square: 0.6002\n",
      "Epoch 96/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0165 - r_square: 0.7459 - val_loss: 0.0225 - val_r_square: 0.6299\n",
      "Epoch 97/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0165 - r_square: 0.7452 - val_loss: 0.0221 - val_r_square: 0.6176\n",
      "Epoch 98/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0164 - r_square: 0.7444 - val_loss: 0.0225 - val_r_square: 0.6163\n",
      "Epoch 99/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0165 - r_square: 0.7440 - val_loss: 0.0219 - val_r_square: 0.6034\n",
      "Epoch 100/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0164 - r_square: 0.7411 - val_loss: 0.0223 - val_r_square: 0.6233\n",
      "Epoch 1/100\n",
      "   5/4073 [..............................] - ETA: 53s - loss: 0.1093 - r_square: -333.9680    WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0060s vs `on_train_batch_end` time: 0.0067s). Check your callbacks.\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0520 - r_square: 0.1309 - val_loss: 0.0430 - val_r_square: 0.3002\n",
      "Epoch 2/100\n",
      "4073/4073 [==============================] - 37s 9ms/step - loss: 0.0388 - r_square: 0.4195 - val_loss: 0.0370 - val_r_square: 0.4085\n",
      "Epoch 3/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0341 - r_square: 0.5022 - val_loss: 0.0347 - val_r_square: 0.4852\n",
      "Epoch 4/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0316 - r_square: 0.5412 - val_loss: 0.0308 - val_r_square: 0.5500\n",
      "Epoch 5/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0295 - r_square: 0.5730 - val_loss: 0.0298 - val_r_square: 0.5500\n",
      "Epoch 6/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0281 - r_square: 0.5928 - val_loss: 0.0281 - val_r_square: 0.5680\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0270 - r_square: 0.6053 - val_loss: 0.0282 - val_r_square: 0.5782\n",
      "Epoch 8/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0262 - r_square: 0.6162 - val_loss: 0.0272 - val_r_square: 0.5951\n",
      "Epoch 9/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0254 - r_square: 0.6268 - val_loss: 0.0270 - val_r_square: 0.5928\n",
      "Epoch 10/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0247 - r_square: 0.6354 - val_loss: 0.0268 - val_r_square: 0.5762\n",
      "Epoch 11/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0241 - r_square: 0.6436 - val_loss: 0.0258 - val_r_square: 0.5922\n",
      "Epoch 12/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0236 - r_square: 0.6500 - val_loss: 0.0258 - val_r_square: 0.6104\n",
      "Epoch 13/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0232 - r_square: 0.6544 - val_loss: 0.0257 - val_r_square: 0.5876\n",
      "Epoch 14/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0229 - r_square: 0.6588 - val_loss: 0.0248 - val_r_square: 0.6095\n",
      "Epoch 15/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0224 - r_square: 0.6643 - val_loss: 0.0253 - val_r_square: 0.5836\n",
      "Epoch 16/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0221 - r_square: 0.6691 - val_loss: 0.0249 - val_r_square: 0.6153\n",
      "Epoch 17/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0218 - r_square: 0.6717 - val_loss: 0.0249 - val_r_square: 0.6163\n",
      "Epoch 18/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0214 - r_square: 0.6772 - val_loss: 0.0245 - val_r_square: 0.6082\n",
      "Epoch 19/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0213 - r_square: 0.6805 - val_loss: 0.0247 - val_r_square: 0.6222\n",
      "Epoch 20/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0210 - r_square: 0.6838 - val_loss: 0.0240 - val_r_square: 0.6282\n",
      "Epoch 21/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0209 - r_square: 0.6852 - val_loss: 0.0244 - val_r_square: 0.6031\n",
      "Epoch 22/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0206 - r_square: 0.6888 - val_loss: 0.0235 - val_r_square: 0.6292\n",
      "Epoch 23/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0204 - r_square: 0.6907 - val_loss: 0.0240 - val_r_square: 0.6162\n",
      "Epoch 24/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0202 - r_square: 0.6940 - val_loss: 0.0238 - val_r_square: 0.6251\n",
      "Epoch 25/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0201 - r_square: 0.6929 - val_loss: 0.0239 - val_r_square: 0.6328\n",
      "Epoch 26/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0200 - r_square: 0.6956 - val_loss: 0.0238 - val_r_square: 0.6178\n",
      "Epoch 27/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0197 - r_square: 0.6986 - val_loss: 0.0236 - val_r_square: 0.6247\n",
      "Epoch 28/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0196 - r_square: 0.7008 - val_loss: 0.0241 - val_r_square: 0.6296\n",
      "Epoch 29/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0196 - r_square: 0.7011 - val_loss: 0.0229 - val_r_square: 0.6312\n",
      "Epoch 30/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0195 - r_square: 0.7019 - val_loss: 0.0230 - val_r_square: 0.6294\n",
      "Epoch 31/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0193 - r_square: 0.7056 - val_loss: 0.0231 - val_r_square: 0.6256\n",
      "Epoch 32/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0192 - r_square: 0.7055 - val_loss: 0.0230 - val_r_square: 0.6410\n",
      "Epoch 33/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0191 - r_square: 0.7065 - val_loss: 0.0230 - val_r_square: 0.6477\n",
      "Epoch 34/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0190 - r_square: 0.7069 - val_loss: 0.0233 - val_r_square: 0.6291\n",
      "Epoch 35/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0189 - r_square: 0.7082 - val_loss: 0.0224 - val_r_square: 0.6361\n",
      "Epoch 36/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0188 - r_square: 0.7126 - val_loss: 0.0226 - val_r_square: 0.6319\n",
      "Epoch 37/100\n",
      "4073/4073 [==============================] - 37s 9ms/step - loss: 0.0187 - r_square: 0.7129 - val_loss: 0.0225 - val_r_square: 0.6346\n",
      "Epoch 38/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0187 - r_square: 0.7125 - val_loss: 0.0228 - val_r_square: 0.6287\n",
      "Epoch 39/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0186 - r_square: 0.7133 - val_loss: 0.0228 - val_r_square: 0.6314\n",
      "Epoch 40/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0183 - r_square: 0.7154 - val_loss: 0.0228 - val_r_square: 0.6361\n",
      "Epoch 41/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0183 - r_square: 0.7184 - val_loss: 0.0223 - val_r_square: 0.6422\n",
      "Epoch 42/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0182 - r_square: 0.7172 - val_loss: 0.0223 - val_r_square: 0.6368\n",
      "Epoch 43/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0180 - r_square: 0.7200 - val_loss: 0.0220 - val_r_square: 0.6440\n",
      "Epoch 44/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0181 - r_square: 0.7192 - val_loss: 0.0223 - val_r_square: 0.6310\n",
      "Epoch 45/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0181 - r_square: 0.7200 - val_loss: 0.0230 - val_r_square: 0.6476\n",
      "Epoch 46/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0179 - r_square: 0.7219 - val_loss: 0.0230 - val_r_square: 0.6326\n",
      "Epoch 47/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0180 - r_square: 0.7227 - val_loss: 0.0228 - val_r_square: 0.6191\n",
      "Epoch 48/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0178 - r_square: 0.7231 - val_loss: 0.0229 - val_r_square: 0.6271\n",
      "Epoch 49/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0179 - r_square: 0.7232 - val_loss: 0.0222 - val_r_square: 0.6454\n",
      "Epoch 50/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0176 - r_square: 0.7274 - val_loss: 0.0221 - val_r_square: 0.6474\n",
      "Epoch 51/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0175 - r_square: 0.7283 - val_loss: 0.0226 - val_r_square: 0.6368\n",
      "Epoch 52/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0174 - r_square: 0.7307 - val_loss: 0.0224 - val_r_square: 0.6223\n",
      "Epoch 53/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0175 - r_square: 0.7280 - val_loss: 0.0226 - val_r_square: 0.6380\n",
      "Epoch 54/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0175 - r_square: 0.7299 - val_loss: 0.0224 - val_r_square: 0.6430\n",
      "Epoch 55/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0173 - r_square: 0.7312 - val_loss: 0.0218 - val_r_square: 0.6496\n",
      "Epoch 56/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0172 - r_square: 0.7323 - val_loss: 0.0222 - val_r_square: 0.6418\n",
      "Epoch 57/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0175 - r_square: 0.7263 - val_loss: 0.0224 - val_r_square: 0.6398\n",
      "Epoch 58/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0172 - r_square: 0.7302 - val_loss: 0.0224 - val_r_square: 0.6227\n",
      "Epoch 59/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0173 - r_square: 0.7309 - val_loss: 0.0228 - val_r_square: 0.6380\n",
      "Epoch 60/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0171 - r_square: 0.7336 - val_loss: 0.0219 - val_r_square: 0.6349\n",
      "Epoch 61/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0171 - r_square: 0.7342 - val_loss: 0.0223 - val_r_square: 0.6462\n",
      "Epoch 62/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0172 - r_square: 0.7319 - val_loss: 0.0224 - val_r_square: 0.6333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0172 - r_square: 0.7326 - val_loss: 0.0220 - val_r_square: 0.6423\n",
      "Epoch 64/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0173 - r_square: 0.7312 - val_loss: 0.0226 - val_r_square: 0.6216\n",
      "Epoch 65/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0171 - r_square: 0.7345 - val_loss: 0.0225 - val_r_square: 0.6171\n",
      "Epoch 66/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0171 - r_square: 0.7358 - val_loss: 0.0231 - val_r_square: 0.6401\n",
      "Epoch 67/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0170 - r_square: 0.7355 - val_loss: 0.0226 - val_r_square: 0.6308\n",
      "Epoch 68/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0169 - r_square: 0.7365 - val_loss: 0.0223 - val_r_square: 0.6206\n",
      "Epoch 69/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0167 - r_square: 0.7395 - val_loss: 0.0220 - val_r_square: 0.6404\n",
      "Epoch 70/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0169 - r_square: 0.7362 - val_loss: 0.0224 - val_r_square: 0.6305\n",
      "Epoch 71/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0167 - r_square: 0.7387 - val_loss: 0.0220 - val_r_square: 0.6346\n",
      "Epoch 72/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0168 - r_square: 0.7386 - val_loss: 0.0219 - val_r_square: 0.6488\n",
      "Epoch 73/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0168 - r_square: 0.7365 - val_loss: 0.0232 - val_r_square: 0.6284\n",
      "Epoch 74/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0168 - r_square: 0.7366 - val_loss: 0.0221 - val_r_square: 0.6425\n",
      "Epoch 75/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0168 - r_square: 0.7390 - val_loss: 0.0219 - val_r_square: 0.6279\n",
      "Epoch 76/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0166 - r_square: 0.7384 - val_loss: 0.0217 - val_r_square: 0.6383\n",
      "Epoch 77/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0166 - r_square: 0.7428 - val_loss: 0.0222 - val_r_square: 0.6499\n",
      "Epoch 78/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0165 - r_square: 0.7436 - val_loss: 0.0219 - val_r_square: 0.6356\n",
      "Epoch 79/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0166 - r_square: 0.7437 - val_loss: 0.0224 - val_r_square: 0.6299\n",
      "Epoch 80/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0164 - r_square: 0.7444 - val_loss: 0.0219 - val_r_square: 0.6473\n",
      "Epoch 81/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0166 - r_square: 0.7419 - val_loss: 0.0218 - val_r_square: 0.6332\n",
      "Epoch 82/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0165 - r_square: 0.7438 - val_loss: 0.0218 - val_r_square: 0.6407\n",
      "Epoch 83/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0166 - r_square: 0.7425 - val_loss: 0.0224 - val_r_square: 0.6404\n",
      "Epoch 84/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0165 - r_square: 0.7417 - val_loss: 0.0218 - val_r_square: 0.6411\n",
      "Epoch 85/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0164 - r_square: 0.7436 - val_loss: 0.0219 - val_r_square: 0.6441\n",
      "Epoch 86/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0165 - r_square: 0.7415 - val_loss: 0.0228 - val_r_square: 0.6503\n",
      "Epoch 87/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0162 - r_square: 0.7461 - val_loss: 0.0218 - val_r_square: 0.6439\n",
      "Epoch 88/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0163 - r_square: 0.7462 - val_loss: 0.0218 - val_r_square: 0.6353\n",
      "Epoch 89/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0163 - r_square: 0.7453 - val_loss: 0.0224 - val_r_square: 0.6464\n",
      "Epoch 90/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0166 - r_square: 0.7413 - val_loss: 0.0221 - val_r_square: 0.6421\n",
      "Epoch 91/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0166 - r_square: 0.7437 - val_loss: 0.0223 - val_r_square: 0.6339\n",
      "Epoch 92/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0162 - r_square: 0.7479 - val_loss: 0.0222 - val_r_square: 0.6523\n",
      "Epoch 93/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0162 - r_square: 0.7475 - val_loss: 0.0221 - val_r_square: 0.6407\n",
      "Epoch 94/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0162 - r_square: 0.7502 - val_loss: 0.0226 - val_r_square: 0.6369\n",
      "Epoch 95/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0162 - r_square: 0.7465 - val_loss: 0.0224 - val_r_square: 0.6461\n",
      "Epoch 96/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0162 - r_square: 0.7487 - val_loss: 0.0218 - val_r_square: 0.6445\n",
      "Epoch 97/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0165 - r_square: 0.7454 - val_loss: 0.0223 - val_r_square: 0.6382\n",
      "Epoch 98/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0162 - r_square: 0.7509 - val_loss: 0.0219 - val_r_square: 0.6454\n",
      "Epoch 99/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0162 - r_square: 0.7530 - val_loss: 0.0219 - val_r_square: 0.6426\n",
      "Epoch 100/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0160 - r_square: 0.7517 - val_loss: 0.0220 - val_r_square: 0.6366\n",
      "Epoch 1/100\n",
      "   1/4073 [..............................] - ETA: 29:22 - loss: 0.1227 - r_square: -1779.7897WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_train_batch_end` time: 0.0056s). Check your callbacks.\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0511 - r_square: 0.1410 - val_loss: 0.0414 - val_r_square: 0.3581\n",
      "Epoch 2/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0381 - r_square: 0.4333 - val_loss: 0.0356 - val_r_square: 0.4681\n",
      "Epoch 3/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0336 - r_square: 0.5177 - val_loss: 0.0326 - val_r_square: 0.5049\n",
      "Epoch 4/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0310 - r_square: 0.5564 - val_loss: 0.0317 - val_r_square: 0.5324\n",
      "Epoch 5/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0291 - r_square: 0.5819 - val_loss: 0.0291 - val_r_square: 0.5508\n",
      "Epoch 6/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0277 - r_square: 0.5990 - val_loss: 0.0282 - val_r_square: 0.5698\n",
      "Epoch 7/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0267 - r_square: 0.6101 - val_loss: 0.0275 - val_r_square: 0.5872\n",
      "Epoch 8/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0259 - r_square: 0.6228 - val_loss: 0.0271 - val_r_square: 0.5775\n",
      "Epoch 9/100\n",
      "4073/4073 [==============================] - 32s 8ms/step - loss: 0.0251 - r_square: 0.6329 - val_loss: 0.0266 - val_r_square: 0.5878\n",
      "Epoch 10/100\n",
      "4073/4073 [==============================] - 36s 9ms/step - loss: 0.0244 - r_square: 0.6398 - val_loss: 0.0257 - val_r_square: 0.6024\n",
      "Epoch 11/100\n",
      "4073/4073 [==============================] - 36s 9ms/step - loss: 0.0239 - r_square: 0.6465 - val_loss: 0.0257 - val_r_square: 0.6013\n",
      "Epoch 12/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0234 - r_square: 0.6522 - val_loss: 0.0251 - val_r_square: 0.5974\n",
      "Epoch 13/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0230 - r_square: 0.6574 - val_loss: 0.0245 - val_r_square: 0.6064\n",
      "Epoch 14/100\n",
      "4073/4073 [==============================] - 39s 10ms/step - loss: 0.0226 - r_square: 0.6632 - val_loss: 0.0252 - val_r_square: 0.5980\n",
      "Epoch 15/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0222 - r_square: 0.6684 - val_loss: 0.0243 - val_r_square: 0.6144\n",
      "Epoch 16/100\n",
      "4073/4073 [==============================] - 36s 9ms/step - loss: 0.0219 - r_square: 0.6716 - val_loss: 0.0240 - val_r_square: 0.6112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "4073/4073 [==============================] - 37s 9ms/step - loss: 0.0215 - r_square: 0.6755 - val_loss: 0.0239 - val_r_square: 0.6250\n",
      "Epoch 18/100\n",
      "4073/4073 [==============================] - 38s 9ms/step - loss: 0.0213 - r_square: 0.6770 - val_loss: 0.0238 - val_r_square: 0.6130\n",
      "Epoch 19/100\n",
      "4073/4073 [==============================] - 37s 9ms/step - loss: 0.0211 - r_square: 0.6821 - val_loss: 0.0237 - val_r_square: 0.5944\n",
      "Epoch 20/100\n",
      "4073/4073 [==============================] - 36s 9ms/step - loss: 0.0209 - r_square: 0.6835 - val_loss: 0.0232 - val_r_square: 0.6381\n",
      "Epoch 21/100\n",
      "4073/4073 [==============================] - 36s 9ms/step - loss: 0.0207 - r_square: 0.6868 - val_loss: 0.0234 - val_r_square: 0.6121\n",
      "Epoch 22/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0204 - r_square: 0.6908 - val_loss: 0.0232 - val_r_square: 0.6293\n",
      "Epoch 23/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0203 - r_square: 0.6937 - val_loss: 0.0234 - val_r_square: 0.6194\n",
      "Epoch 24/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0201 - r_square: 0.6936 - val_loss: 0.0237 - val_r_square: 0.6292\n",
      "Epoch 25/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0199 - r_square: 0.6972 - val_loss: 0.0231 - val_r_square: 0.6320\n",
      "Epoch 26/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0197 - r_square: 0.7009 - val_loss: 0.0229 - val_r_square: 0.6258\n",
      "Epoch 27/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0196 - r_square: 0.7022 - val_loss: 0.0229 - val_r_square: 0.6199\n",
      "Epoch 28/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0195 - r_square: 0.7036 - val_loss: 0.0230 - val_r_square: 0.6191\n",
      "Epoch 29/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0193 - r_square: 0.7064 - val_loss: 0.0225 - val_r_square: 0.6180\n",
      "Epoch 30/100\n",
      "4073/4073 [==============================] - 36s 9ms/step - loss: 0.0191 - r_square: 0.7061 - val_loss: 0.0229 - val_r_square: 0.6267\n",
      "Epoch 31/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0190 - r_square: 0.7070 - val_loss: 0.0229 - val_r_square: 0.6153\n",
      "Epoch 32/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0189 - r_square: 0.7085 - val_loss: 0.0229 - val_r_square: 0.6164\n",
      "Epoch 33/100\n",
      "4073/4073 [==============================] - 36s 9ms/step - loss: 0.0189 - r_square: 0.7101 - val_loss: 0.0226 - val_r_square: 0.6170\n",
      "Epoch 34/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0187 - r_square: 0.7127 - val_loss: 0.0241 - val_r_square: 0.6126\n",
      "Epoch 35/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0186 - r_square: 0.7133 - val_loss: 0.0229 - val_r_square: 0.6198\n",
      "Epoch 36/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0185 - r_square: 0.7161 - val_loss: 0.0223 - val_r_square: 0.6244\n",
      "Epoch 37/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0185 - r_square: 0.7172 - val_loss: 0.0225 - val_r_square: 0.6318\n",
      "Epoch 38/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0183 - r_square: 0.7180 - val_loss: 0.0224 - val_r_square: 0.6361\n",
      "Epoch 39/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0182 - r_square: 0.7195 - val_loss: 0.0225 - val_r_square: 0.6456\n",
      "Epoch 40/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0181 - r_square: 0.7226 - val_loss: 0.0227 - val_r_square: 0.6352\n",
      "Epoch 41/100\n",
      "4073/4073 [==============================] - 37s 9ms/step - loss: 0.0181 - r_square: 0.7223 - val_loss: 0.0218 - val_r_square: 0.6452\n",
      "Epoch 42/100\n",
      "4073/4073 [==============================] - 36s 9ms/step - loss: 0.0179 - r_square: 0.7251 - val_loss: 0.0220 - val_r_square: 0.6392\n",
      "Epoch 43/100\n",
      "4073/4073 [==============================] - 74s 18ms/step - loss: 0.0180 - r_square: 0.7246 - val_loss: 0.0222 - val_r_square: 0.6236\n",
      "Epoch 44/100\n",
      "4073/4073 [==============================] - 89s 22ms/step - loss: 0.0178 - r_square: 0.7250 - val_loss: 0.0220 - val_r_square: 0.6391\n",
      "Epoch 45/100\n",
      "4073/4073 [==============================] - 86s 21ms/step - loss: 0.0178 - r_square: 0.7253 - val_loss: 0.0222 - val_r_square: 0.6410\n",
      "Epoch 46/100\n",
      "4073/4073 [==============================] - 86s 21ms/step - loss: 0.0177 - r_square: 0.7278 - val_loss: 0.0219 - val_r_square: 0.6371\n",
      "Epoch 47/100\n",
      "4073/4073 [==============================] - 37s 9ms/step - loss: 0.0178 - r_square: 0.7263 - val_loss: 0.0220 - val_r_square: 0.6327\n",
      "Epoch 48/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0176 - r_square: 0.7287 - val_loss: 0.0220 - val_r_square: 0.6249\n",
      "Epoch 49/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0176 - r_square: 0.7298 - val_loss: 0.0222 - val_r_square: 0.6409\n",
      "Epoch 50/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0175 - r_square: 0.7295 - val_loss: 0.0218 - val_r_square: 0.6325\n",
      "Epoch 51/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0175 - r_square: 0.7306 - val_loss: 0.0222 - val_r_square: 0.6020\n",
      "Epoch 52/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0173 - r_square: 0.7335 - val_loss: 0.0222 - val_r_square: 0.6455\n",
      "Epoch 53/100\n",
      "4073/4073 [==============================] - 36s 9ms/step - loss: 0.0172 - r_square: 0.7359 - val_loss: 0.0219 - val_r_square: 0.6232\n",
      "Epoch 54/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0175 - r_square: 0.7308 - val_loss: 0.0221 - val_r_square: 0.6478\n",
      "Epoch 55/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0172 - r_square: 0.7338 - val_loss: 0.0225 - val_r_square: 0.6384\n",
      "Epoch 56/100\n",
      "4073/4073 [==============================] - 32s 8ms/step - loss: 0.0172 - r_square: 0.7343 - val_loss: 0.0225 - val_r_square: 0.6260\n",
      "Epoch 57/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0172 - r_square: 0.7355 - val_loss: 0.0221 - val_r_square: 0.6143\n",
      "Epoch 58/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0172 - r_square: 0.7339 - val_loss: 0.0220 - val_r_square: 0.6353\n",
      "Epoch 59/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0171 - r_square: 0.7379 - val_loss: 0.0219 - val_r_square: 0.6301\n",
      "Epoch 60/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0172 - r_square: 0.7325 - val_loss: 0.0217 - val_r_square: 0.6310\n",
      "Epoch 61/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0171 - r_square: 0.7361 - val_loss: 0.0218 - val_r_square: 0.6339\n",
      "Epoch 62/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0169 - r_square: 0.7392 - val_loss: 0.0220 - val_r_square: 0.6241\n",
      "Epoch 63/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0170 - r_square: 0.7392 - val_loss: 0.0219 - val_r_square: 0.6327\n",
      "Epoch 64/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0169 - r_square: 0.7392 - val_loss: 0.0219 - val_r_square: 0.6277\n",
      "Epoch 65/100\n",
      "4073/4073 [==============================] - 32s 8ms/step - loss: 0.0169 - r_square: 0.7391 - val_loss: 0.0216 - val_r_square: 0.6461\n",
      "Epoch 66/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0168 - r_square: 0.7400 - val_loss: 0.0220 - val_r_square: 0.6503\n",
      "Epoch 67/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0169 - r_square: 0.7412 - val_loss: 0.0216 - val_r_square: 0.6180\n",
      "Epoch 68/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0167 - r_square: 0.7409 - val_loss: 0.0219 - val_r_square: 0.6340\n",
      "Epoch 69/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0168 - r_square: 0.7415 - val_loss: 0.0222 - val_r_square: 0.6389\n",
      "Epoch 70/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0167 - r_square: 0.7436 - val_loss: 0.0217 - val_r_square: 0.6370\n",
      "Epoch 71/100\n",
      "4073/4073 [==============================] - 36s 9ms/step - loss: 0.0166 - r_square: 0.7438 - val_loss: 0.0216 - val_r_square: 0.6405\n",
      "Epoch 72/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0165 - r_square: 0.7443 - val_loss: 0.0216 - val_r_square: 0.6278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0167 - r_square: 0.7417 - val_loss: 0.0216 - val_r_square: 0.6416\n",
      "Epoch 74/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0165 - r_square: 0.7462 - val_loss: 0.0217 - val_r_square: 0.6371\n",
      "Epoch 75/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0167 - r_square: 0.7445 - val_loss: 0.0219 - val_r_square: 0.6303\n",
      "Epoch 76/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0165 - r_square: 0.7487 - val_loss: 0.0222 - val_r_square: 0.6461\n",
      "Epoch 77/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0166 - r_square: 0.7443 - val_loss: 0.0216 - val_r_square: 0.6402\n",
      "Epoch 78/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0164 - r_square: 0.7499 - val_loss: 0.0218 - val_r_square: 0.6468\n",
      "Epoch 79/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0165 - r_square: 0.7475 - val_loss: 0.0218 - val_r_square: 0.6401\n",
      "Epoch 80/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0164 - r_square: 0.7493 - val_loss: 0.0219 - val_r_square: 0.6024\n",
      "Epoch 81/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0163 - r_square: 0.7501 - val_loss: 0.0216 - val_r_square: 0.6461\n",
      "Epoch 82/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0164 - r_square: 0.7483 - val_loss: 0.0221 - val_r_square: 0.6332\n",
      "Epoch 83/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0163 - r_square: 0.7508 - val_loss: 0.0218 - val_r_square: 0.6354\n",
      "Epoch 84/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0163 - r_square: 0.7510 - val_loss: 0.0216 - val_r_square: 0.6251\n",
      "Epoch 85/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0163 - r_square: 0.7513 - val_loss: 0.0217 - val_r_square: 0.6466\n",
      "Epoch 86/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0163 - r_square: 0.7513 - val_loss: 0.0219 - val_r_square: 0.6404\n",
      "Epoch 87/100\n",
      "4073/4073 [==============================] - 35s 8ms/step - loss: 0.0162 - r_square: 0.7526 - val_loss: 0.0219 - val_r_square: 0.6248\n",
      "Epoch 88/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0162 - r_square: 0.7518 - val_loss: 0.0216 - val_r_square: 0.6377\n",
      "Epoch 89/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0163 - r_square: 0.7519 - val_loss: 0.0220 - val_r_square: 0.6253\n",
      "Epoch 90/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0161 - r_square: 0.7531 - val_loss: 0.0220 - val_r_square: 0.6382\n",
      "Epoch 91/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0164 - r_square: 0.7499 - val_loss: 0.0216 - val_r_square: 0.6312\n",
      "Epoch 92/100\n",
      "4073/4073 [==============================] - 35s 9ms/step - loss: 0.0163 - r_square: 0.7515 - val_loss: 0.0215 - val_r_square: 0.6456\n",
      "Epoch 93/100\n",
      "4073/4073 [==============================] - 37s 9ms/step - loss: 0.0162 - r_square: 0.7527 - val_loss: 0.0220 - val_r_square: 0.6384\n",
      "Epoch 94/100\n",
      "4073/4073 [==============================] - 36s 9ms/step - loss: 0.0160 - r_square: 0.7547 - val_loss: 0.0218 - val_r_square: 0.6214\n",
      "Epoch 95/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0161 - r_square: 0.7544 - val_loss: 0.0213 - val_r_square: 0.6495\n",
      "Epoch 96/100\n",
      "4073/4073 [==============================] - 34s 8ms/step - loss: 0.0161 - r_square: 0.7506 - val_loss: 0.0215 - val_r_square: 0.6406\n",
      "Epoch 97/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0162 - r_square: 0.7529 - val_loss: 0.0218 - val_r_square: 0.6451\n",
      "Epoch 98/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0161 - r_square: 0.7541 - val_loss: 0.0218 - val_r_square: 0.6321\n",
      "Epoch 99/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0162 - r_square: 0.7537 - val_loss: 0.0220 - val_r_square: 0.6277\n",
      "Epoch 100/100\n",
      "4073/4073 [==============================] - 33s 8ms/step - loss: 0.0161 - r_square: 0.7494 - val_loss: 0.0218 - val_r_square: 0.6354\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_mae'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m             \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:203\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m         tuner_utils\u001b[38;5;241m.\u001b[39mvalidate_trial_results(\n\u001b[0;32m    197\u001b[0m             results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuner.run_trial()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m         ),\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mupdate_trial(\n\u001b[0;32m    200\u001b[0m             trial\u001b[38;5;241m.\u001b[39mtrial_id,\n\u001b[0;32m    201\u001b[0m             \u001b[38;5;66;03m# Convert to dictionary before calling `update_trial()`\u001b[39;00m\n\u001b[0;32m    202\u001b[0m             \u001b[38;5;66;03m# to pass it from gRPC.\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m             \u001b[43mtuner_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_metrics_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m                \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    207\u001b[0m             step\u001b[38;5;241m=\u001b[39mtuner_utils\u001b[38;5;241m.\u001b[39mget_best_step(results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective),\n\u001b[0;32m    208\u001b[0m         )\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner_utils.py:266\u001b[0m, in \u001b[0;36mconvert_to_metrics_dict\u001b[1;34m(results, objective)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# List of multiple exectuion results to be averaged.\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# Check this case first to deal each case individually to check for errors.\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m average_metrics_dicts(\n\u001b[1;32m--> 266\u001b[0m         [convert_to_metrics_dict(elem, objective) \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[0;32m    267\u001b[0m     )\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# Single value.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, np\u001b[38;5;241m.\u001b[39mfloating)):\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner_utils.py:266\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# List of multiple exectuion results to be averaged.\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# Check this case first to deal each case individually to check for errors.\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m average_metrics_dicts(\n\u001b[1;32m--> 266\u001b[0m         [\u001b[43mconvert_to_metrics_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[0;32m    267\u001b[0m     )\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# Single value.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, np\u001b[38;5;241m.\u001b[39mfloating)):\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner_utils.py:279\u001b[0m, in \u001b[0;36mconvert_to_metrics_dict\u001b[1;34m(results, objective)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# A History.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mHistory):\n\u001b[1;32m--> 279\u001b[0m     best_value, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_get_best_value_and_best_epoch_from_history\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_value\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner_utils.py:250\u001b[0m, in \u001b[0;36m_get_best_value_and_best_epoch_from_history\u001b[1;34m(history, objective)\u001b[0m\n\u001b[0;32m    248\u001b[0m best_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch, metrics \u001b[38;5;129;01min\u001b[39;00m epoch_metrics\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 250\u001b[0m     objective_value \u001b[38;5;241m=\u001b[39m \u001b[43mobjective\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;66;03m# Support multi-objective.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m objective\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m metrics:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_tuner\\engine\\objective.py:55\u001b[0m, in \u001b[0;36mObjective.get_value\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, logs):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;124;03m\"\"\"Get the objective value from the metrics logs.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m        The objective value.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlogs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_mae'"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train, y_train,\n",
    "             epochs=100,\n",
    "             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4016d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in project\\Velocity Field\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x0000015988D65520>\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eef0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c4c5c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "906/906 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6543499371097048"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ann1.predict(x_test)\n",
    "y_pred = sc.inverse_transform(y_pred)\n",
    "y_actual = sc.inverse_transform(y_test)\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\n",
    "r2 = r2_score(y_actual,y_pred)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4dd151f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1089,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_pred[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad4c8790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1da6a08a4c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAP+UlEQVR4nO3dX4xc5X3G8e+z6107tWmDS0wsY9UJ8kUQagzaurRUES1t5FqRALWgcBH5wtJyEaQgpRdWKhV6R6tCyhWSKVacihJQAwJVqA2yUiGkymWhxjZ1mhDkEGPLTvgjA7G99u6vF3Msbel5z86eOefM7L7PRxrNzJk5c34+nmfO7PvOe15FBGa28o0NuwAz64bDbpYJh90sEw67WSYcdrNMOOxmmVg1yMqSdgCPAOPAP0TEg1XPn5xYG2tWf3qQTQ5M8+muxvlV5Z99c2tU8XpLW75YDSQeUlUPaeL1KrdTWUOi+DrrVKxX3embeNQ9xZXO8zGzcaH0Dau6/eySxoEfA38CnABeAe6OiP9OrfPr6zbF715/T63tNWXsVxeTj81uWFu6/IOtk+nXmy1fPvlxer+uOpcOxths+WPjF9LrjJ+/VP5a59L/Vp1LFA7o3IXS5XG+fDkAF9KPxWz5tmKu4gMi8eERdT9w6liGv0E5GAc4G++Vhn2Qr/HbgTcj4q2ImAW+B9w2wOuZWYsGCfsm4OcL7p8olpnZCBok7GVfFf7f9x5J05JmJM1cvPjxAJszs0EMEvYTwOYF968BTn7ySRGxNyKmImJqYqL8b2Iza98gYX8F2Crpc5Imga8CzzdTlpk1rXbXW0RcknQv8G/0ut72RcQbjVXWh1R31PzkeHKdsXd/kXxs1a9NlC5f817FblJ5t9x4olUdYOxiupU31eqeanGHdKt7nRZ3qGh1r9HiDulW95ibS65Tq2V9Gbaed2mgfvaIeAF4oaFazKxF/gWdWSYcdrNMOOxmmXDYzTIxUAPdkkW6BT1SY03G0oNQuFjemrvq9EfpEip+3z23trw1vmpQy6rz5TVMfpD+XfqqD84lH9NHvypdHh+XLweIc+dLl89fSrfgU9ESXvn78/RKS1/HOuUju1kmHHazTDjsZplw2M0y4bCbZcJhN8tEp11vmp9n7Gx5t9NHX1hfuvz076QHtVz7+z8rXb5708vJdf5s3dnkY989e6R0+d8/cmdync8e+GX5A+++n1wnZtPdcpWDQ1Lma3R7Kf05r7Glv17Md3TcqOriSwxKqr+tlTWwxkd2s0w47GaZcNjNMuGwm2XCYTfLRO1JIur4jYkN8Xvr/7z8wdSgjarW6fFES32dFu0qFYNxKic6SKnTel7x/5Rswa8zoAU6G9RSa8BN9Qs2/HrLrzW+rUkizGwZcdjNMuGwm2XCYTfLhMNulgmH3SwTAw2EkXQc+BCYAy5FxFTtF+uqu6dOt1zVKqnumYrutcruTp//rZq712prYtTbH0ZEYuiXmY0Kf403y8SgYQ/gB5JelTTdREFm1o5Bv8bfHBEnJW0AXpT0o4h4aeETig+BaYA1Y+sG3JyZ1TXQkT0iThbXZ4Bnge0lz9kbEVMRMTU59qlBNmdmA6gddklrJV1x+TbwZeBoU4WZWbMG+Rp/NfCseuf9WgX8U0T8a/1KEqVUnCstORptNr1K1VnKUt1yUXMapXQRDbeLNv16DXdvNT66zWqpHfaIeAv4YoO1mFmL3PVmlgmH3SwTDrtZJhx2s0x0OiMMBMwnWq/Hys8np/GKz6PEDCAxOZFep6KlPtmyPgrnSmu6xX3UecBL4zJ7B5nly2E3y4TDbpYJh90sEw67WSYcdrNMdNv1Fiy5eyui4vMoMfVS5cCVGjRRsZsS55pr/DxzI86DXUafj+xmmXDYzTLhsJtlwmE3y4TDbpaJjlvjg0i0oGtVjc+dxGmpKgfPVLQax1hivYpTT1W2uqekTqfVtA5byFXxbxqJlvrEoKmcBsj4yG6WCYfdLBMOu1kmHHazTDjsZplw2M0ysWjXm6R9wFeAMxFxfbFsPfAUsAU4DtwVEe/3tcXUwJHZqpPDJdTpNkl1wVS9XqLm6s3U616r1ZU3Cl1boy6jLraUfo7s3wF2fGLZHuBARGwFDhT3zWyELRr2Ygrm9z6x+DZgf3F7P3B7s2WZWdPq/s1+dUScAiiuNzRXkpm1ofWfy0qaBqYB1mht25szs4S6R/bTkjYCFNdnUk+MiL0RMRURU5NaU3NzZjaoumF/HthV3N4FPNdMOWbWln663p4EbgGuknQCuB94EHha0m7gbeDOgSup0+2VGqU2Xj6V1KIqRrel1OliW4ndayMxss0qLRr2iLg78dCtDddiZi3yL+jMMuGwm2XCYTfLhMNuloluz0FXJTVAJnHOOiA5I0xVq3rdASpDV3Xeujot4bH0wT2Na7oGD3ap5CO7WSYcdrNMOOxmmXDYzTLhsJtlwmE3y0T3XW8Ndo9EqoutajxL1SCZ1HRSXQ12qeKBJjYgH9nNMuGwm2XCYTfLhMNulgmH3SwTozMQJkHjHX4eJVq8g4qW8KoBKiuMTz21vPnIbpYJh90sEw67WSYcdrNMOOxmmXDYzTKxaNgl7ZN0RtLRBcsekPSOpEPFZWc/G4sIYm6u9FKvepVfRt18LP1SR8ynL5WrReml9rZq1JDeTqQvVqmfI/t3gB0ly78dEduKywvNlmVmTVs07BHxEvBeB7WYWYsG+Zv9XkmHi6/5V6aeJGla0oykmYtxfoDNmdkg6ob9UeBaYBtwCngo9cSF87NPeH52s6GpFfaIOB0RcxExDzwGbG+2LDNrWq2wS9q44O4dwNHUc81sNCw66k3Sk8AtwFWSTgD3A7dI2gYEcBy4p+8tpkaWLdce/1EYCVajG2vkR7C5K61xi4Y9Iu4uWfx4C7WYWYuW6/HUzJbIYTfLhMNulgmH3SwTHZ+DLtItx/M1PneWw6AXsxHhI7tZJhx2s0w47GaZcNjNMuGwm2XCYTfLRLddb5EegKGxGuckq9Ndt1yNwmCXuueNs5GQUVrM8uawm2XCYTfLhMNulgmH3SwTDrtZJjoe9ZaW7pLLbGTbKHSx2YrkI7tZJhx2s0w47GaZcNjNMuGwm2WinxlhNgPfBT4LzAN7I+IRSeuBp4At9GaFuSsi3l90i6nWZpV/7lS1NNcaPJPYTqUOB4C4Zd3a0s87/xLwzYj4AnAT8HVJ1wF7gAMRsRU4UNw3sxG1aNgj4lREvFbc/hA4BmwCbgP2F0/bD9zeUo1m1oAlfaeVtAW4ATgIXB0Rp6D3gQBsSKwzLWlG0sxFLgxYrpnV1XfYJa0Dvg/cFxFn+10vIvZGxFRETE2wuk6NZtaAvsIuaYJe0J+IiGeKxacvz9NeXJ9pp0Qza8KiYZckelM0H4uIhxc89Dywq7i9C3iu+fLMrCn9DIS5GfgacETSoWLZt4AHgacl7QbeBu4cqJIldsn1VqkxeKaqGy21rRHvrmtcV7WHuxm7tGjYI+JlIJWeW5stx8za4l/QmWXCYTfLhMNulgmH3SwTI3NaqqQaref1B5PMLXmNOqfNym6wi1vdR4KP7GaZcNjNMuGwm2XCYTfLhMNulgmH3SwT3Xe9pbphVGPmlxqDZ5qWXTdairvXRp6P7GaZcNjNMuGwm2XCYTfLhMNulgmH3SwTozPqrU7XTaq7ru451DrssmvUcj7fnXVmmb67zWypHHazTDjsZplw2M0y4bCbZaKf6Z82S/qhpGOS3pD0jWL5A5LekXSouOxsv9yWxfzwL3VorPzStIj0xUZeP11vl4BvRsRrkq4AXpX0YvHYtyPi79orz8ya0s/0T6eAy/OwfyjpGLCp7cLMrFlL+q4naQtwA3CwWHSvpMOS9km6MrHOtKQZSTMXuTBYtWZWW99hl7SO3hzt90XEWeBR4FpgG70j/0Nl60XE3oiYioipCVYPXrGZ1dJX2CVN0Av6ExHxDEBEnI6IuYiYBx4DtrdXppkNqp/WeAGPA8ci4uEFyzcueNodwNHmyzOzpvTTGn8z8DXgiKRDxbJvAXdL2gYEcBy4p4X66p2bbjnralCLu8uy009r/MtAWeJeaL4cM2uLf0FnlgmH3SwTDrtZJhx2s0yMzmmpUpo8XVVdXZ6uyqeYspb4yG6WCYfdLBMOu1kmHHazTDjsZplw2M0yMfpdb3U0Pcgj5pp9PbMh8JHdLBMOu1kmHHazTDjsZplw2M0y4bCbZWJldr3VtVzPd+fzyVkffGQ3y4TDbpYJh90sEw67WSYcdrNMLNoaL2kN8BKwunj+P0fE/ZLWA08BW+jNCHNXRLzfXqkdcKu2rWD9HNkvAH8UEV+kN2PrDkk3AXuAAxGxFThQ3DezEbVo2KPno+LuRHEJ4DZgf7F8P3B7GwWaWTP6nbJ5vJjU8QzwYkQcBK6OiFMAxfWGxLrTkmYkzVzkQkNlm9lS9RX2Yh72bcA1wHZJ1/e7gYjYGxFTETE1weqaZZrZoJbUGh8RHwD/DuwATl+eo724PtN0cWbWnEXDLukzkj5d3P4U8MfAj4DngV3F03YBz7VUo5k1oJ+BMBuB/ZLG6X04PB0R/yLpP4CnJe0G3gbubLFOMxvQomGPiMPADSXL3wVubaMoM2uef0FnlgmH3SwTDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhMNulgmH3SwTDrtZJhQdnndN0i+AnxV3rwJ+2dnGy7kG17DSavitiPhM2QOdhv3/bFiaiYipoWzcNbiGDGvw13izTDjsZpkYZtj3DnHbl7mGHtfQs6JrGNrf7GbWLX+NN8vEUMIuaYek/5H0pqShzCQj6bikI5IOSZrpaJv7JJ2RdHTBsvWSXpT0k+L6yiHU8ICkd4p9cUjSzha3v1nSDyUdk/SGpG8UyzvbDxU1dLkf1kj6T0mvFzX8dbG8vf0QEZ1egHHgp8DngUngdeC6IdRxHLiq421+CbgROLpg2d8Ce4rbe4C/GUINDwB/0dE+2AjcWNy+AvgxcF2X+6Gihi73g4B1xe0J4CBwU5v7YRhH9u3AmxHxVkTMAt+jN5XUihcRLwHvfWJxp9NoJWroTESciojXitsfAseATXS4Hypq6Ez0dDqt2jDCvgn4+YL7J+h4RxcC+IGkVyVND2H7l/U1jVYH7pV0uPia3+qfEpdJ2kLvzMV9TyfWcg3Q4X4YZFq1OoYRdpUsG0aXwM0RcSPwp8DXJX1pCDWMikeBa+nN0nsKeKjtDUpaB3wfuC8izra9vT5r6HQ/xADTqtUxjLCfADYvuH8NcLLrIiLiZHF9BniW3p8XwzD0abQi4nTxxpsHHqPlfSFpgl7InoiIZ4rFne6Hshq63g+XRUfTqg0j7K8AWyV9TtIk8FV6U0l1RtJaSVdcvg18GThavVZrhj6N1uU3V+EOWtwXkgQ8DhyLiIcXPNTZfkjV0PF+6H5atS5aHktaInfSawH9KfCXQ9j+5+n1ArwOvNFVDcCT9L4eXqT3DWc38JvAAeAnxfX6IdTwj8AR4HDxZtvY4vb/gN6fbYeBQ8VlZ5f7oaKGLvfDbwP/VWzrKPBXxfLW9oN/QWeWCf+CziwTDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhMNulon/BYveqX9/yn//AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.reshape(y_pred[0,:],(33,33))\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36fa7ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1db20f1b5e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = np.reshape(y_actual[0,:],(33,33))\n",
    "plt.imshow(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d14d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    for i in range(hp.Int('num_layers', 2, 20)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=512,\n",
    "                                            step=32),\n",
    "                               activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='mean_absolute_error',\n",
    "        metrics=['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8b9536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
